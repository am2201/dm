{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c032485-0935-4de6-b21b-4e2d87a3fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe00473-d3b1-4c8c-8ef6-f37f304afb2a",
   "metadata": {},
   "source": [
    "**Iris Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690b70c0-9078-4f70-9fb0-cc8ec51883c5",
   "metadata": {},
   "source": [
    "**Hold-Out Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee5e301-d2ef-4c04-b64c-f2652ffad02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using hold-out method:\n",
      "Naive Bayes: 1.0000\n",
      "K-Nearest Neighbors: 1.0000\n",
      "Decision Tree: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the dataset into training and test sets using hold-out method (75% train, 25% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "nb_classifier = GaussianNB()\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit classifiers to training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "nb_predictions = nb_classifier.predict(X_test)\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "dt_predictions = dt_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each classifier\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "\n",
    "print(\"Accuracy using hold-out method:\")\n",
    "print(f\"Naive Bayes: {nb_accuracy:.4f}\")\n",
    "print(f\"K-Nearest Neighbors: {knn_accuracy:.4f}\")\n",
    "print(f\"Decision Tree: {dt_accuracy:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197edc1f-7760-4d3f-9ec9-f2d893c25fa4",
   "metadata": {},
   "source": [
    "**Random Subsampling Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce9112c6-ffaa-457d-baa6-6ccda049648c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using random subsampling:\n",
      "Naive Bayes: 0.9600\n",
      "K-Nearest Neighbors: 0.9800\n",
      "Decision Tree: 0.9800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's use random subsampling (66.6% train, 33.3% test)\n",
    "X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(X, y, test_size=0.333, random_state=42)\n",
    "\n",
    "# Fit classifiers to subsampled training data\n",
    "nb_classifier.fit(X_train_sub, y_train_sub)\n",
    "knn_classifier.fit(X_train_sub, y_train_sub)\n",
    "dt_classifier.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "# Make predictions on subsampled test data\n",
    "nb_predictions_sub = nb_classifier.predict(X_test_sub)\n",
    "knn_predictions_sub = knn_classifier.predict(X_test_sub)\n",
    "dt_predictions_sub = dt_classifier.predict(X_test_sub)\n",
    "\n",
    "# Calculate accuracy for each classifier with random subsampling\n",
    "nb_accuracy_sub = accuracy_score(y_test_sub, nb_predictions_sub)\n",
    "knn_accuracy_sub = accuracy_score(y_test_sub, knn_predictions_sub)\n",
    "dt_accuracy_sub = accuracy_score(y_test_sub, dt_predictions_sub)\n",
    "\n",
    "print(\"Accuracy using random subsampling:\")\n",
    "print(f\"Naive Bayes: {nb_accuracy_sub:.4f}\")\n",
    "print(f\"K-Nearest Neighbors: {knn_accuracy_sub:.4f}\")\n",
    "print(f\"Decision Tree: {dt_accuracy_sub:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4953a264-444f-419a-99e7-ba12076b7f88",
   "metadata": {},
   "source": [
    "**Cross-Validation Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b30e4c-3c11-459b-bf8b-038c01dec6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using 5-fold cross-validation:\n",
      "Naive Bayes: 0.9533\n",
      "K-Nearest Neighbors: 0.9667\n",
      "Decision Tree: 0.9533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize classifiers\n",
    "nb_classifier_cv = GaussianNB()\n",
    "knn_classifier_cv = KNeighborsClassifier(n_neighbors=3)\n",
    "dt_classifier_cv = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Calculate cross-validated accuracy for each classifier\n",
    "nb_cv_scores = cross_val_score(nb_classifier_cv, X, y, cv=5)\n",
    "knn_cv_scores = cross_val_score(knn_classifier_cv, X, y, cv=5)\n",
    "dt_cv_scores = cross_val_score(dt_classifier_cv, X, y, cv=5)\n",
    "\n",
    "print(\"Accuracy using 5-fold cross-validation:\")\n",
    "print(f\"Naive Bayes: {np.mean(nb_cv_scores):.4f}\")\n",
    "print(f\"K-Nearest Neighbors: {np.mean(knn_cv_scores):.4f}\")\n",
    "print(f\"Decision Tree: {np.mean(dt_cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2e084-945e-4054-8b48-c433fb003c83",
   "metadata": {},
   "source": [
    "**Wine Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e1a216-ca41-4e8d-b826-a1f3a7681b43",
   "metadata": {},
   "source": [
    "**Hold-Out Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e29f93-4be3-47ab-a8e1-4794993e8e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using hold-out method:\n",
      "Naive Bayes: 1.0000\n",
      "K-Nearest Neighbors: 1.0000\n",
      "Decision Tree: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "X_wine, y_wine = wine.data, wine.target\n",
    "\n",
    "# Split the dataset into training and test sets using hold-out method (75% train, 25% test)\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "nb_classifier_ = GaussianNB()\n",
    "knn_classifier_ = KNeighborsClassifier(n_neighbors=3)\n",
    "dt_classifier_ = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit classifiers to training data\n",
    "nb_classifier_.fit(X_train_, y_train_)\n",
    "knn_classifier_.fit(X_train_, y_train_)\n",
    "dt_classifier_.fit(X_train_, y_train_)\n",
    "\n",
    "# Make predictions on test data\n",
    "nb_predictions_ = nb_classifier_.predict(X_test_)\n",
    "knn_predictions_ = knn_classifier_.predict(X_test_)\n",
    "dt_predictions_ = dt_classifier_.predict(X_test_)\n",
    "\n",
    "# Calculate accuracy for each classifier\n",
    "nb_accuracy_ = accuracy_score(y_test_, nb_predictions_)\n",
    "knn_accuracy_ = accuracy_score(y_test_, knn_predictions_)\n",
    "dt_accuracy_ = accuracy_score(y_test_, dt_predictions_)\n",
    "\n",
    "print(\"Accuracy using hold-out method:\")\n",
    "print(f\"Naive Bayes: {nb_accuracy_:.4f}\")\n",
    "print(f\"K-Nearest Neighbors: {knn_accuracy_:.4f}\")\n",
    "print(f\"Decision Tree: {dt_accuracy_:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333fc48f-6981-4e8e-af67-a7499a1b8c11",
   "metadata": {},
   "source": [
    "**Random Subsampling Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12cd708e-15c7-4e0a-85bf-2a2da2a0999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using random subsampling:\n",
      "Naive Bayes: 0.9600\n",
      "K-Nearest Neighbors: 0.9800\n",
      "Decision Tree: 0.9800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's use random subsampling (66.6% train, 33.3% test)\n",
    "X_train_sub_, X_test_sub_, y_train_sub_, y_test_sub_ = train_test_split(X, y, test_size=0.333, random_state=42)\n",
    "\n",
    "# Fit classifiers to subsampled training data\n",
    "nb_classifier.fit(X_train_sub_, y_train_sub_)\n",
    "knn_classifier.fit(X_train_sub_, y_train_sub_)\n",
    "dt_classifier.fit(X_train_sub_, y_train_sub_)\n",
    "\n",
    "# Make predictions on subsampled test data\n",
    "nb_predictions_sub_ = nb_classifier.predict(X_test_sub_)\n",
    "knn_predictions_sub_ = knn_classifier.predict(X_test_sub_)\n",
    "dt_predictions_sub_ = dt_classifier.predict(X_test_sub_)\n",
    "\n",
    "# Calculate accuracy for each classifier with random subsampling\n",
    "nb_accuracy_sub_ = accuracy_score(y_test_sub_, nb_predictions_sub_)\n",
    "knn_accuracy_sub_ = accuracy_score(y_test_sub_, knn_predictions_sub_)\n",
    "dt_accuracy_sub_ = accuracy_score(y_test_sub_, dt_predictions_sub_)\n",
    "\n",
    "print(\"Accuracy using random subsampling:\")\n",
    "print(f\"Naive Bayes: {nb_accuracy_sub_:.4f}\")\n",
    "print(f\"K-Nearest Neighbors: {knn_accuracy_sub_:.4f}\")\n",
    "print(f\"Decision Tree: {dt_accuracy_sub_:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b3757-7b67-473a-8518-cd5632f3a8cf",
   "metadata": {},
   "source": [
    "**Cross-Validation Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7141a5ae-08a5-4447-96df-1c2169a24d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using 5-fold cross-validation:\n",
      "Naive Bayes: 0.9533\n",
      "K-Nearest Neighbors: 0.9667\n",
      "Decision Tree: 0.9533\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers\n",
    "nb_classifier_cv_ = GaussianNB()\n",
    "knn_classifier_cv_ = KNeighborsClassifier(n_neighbors=3)\n",
    "dt_classifier_cv_ = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Calculate cross-validated accuracy for each classifier\n",
    "nb_cv_scores_ = cross_val_score(nb_classifier_cv_, X, y, cv=5)\n",
    "knn_cv_scores_ = cross_val_score(knn_classifier_cv_, X, y, cv=5)\n",
    "dt_cv_scores_ = cross_val_score(dt_classifier_cv_, X, y, cv=5)\n",
    "\n",
    "print(\"Accuracy using 5-fold cross-validation:\")\n",
    "print(f\"Naive Bayes: {np.mean(nb_cv_scores_):.4f}\")\n",
    "print(f\"K-Nearest Neighbors: {np.mean(knn_cv_scores_):.4f}\")\n",
    "print(f\"Decision Tree: {np.mean(dt_cv_scores_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabcf98d-3445-4a4b-bf76-40773583dc45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
